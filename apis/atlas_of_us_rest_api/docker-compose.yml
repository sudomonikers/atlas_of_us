services:
  # Embeddings server using llama-cpp
  embeddings:
    image: ghcr.io/ggerganov/llama.cpp:server
    container_name: atlas_embeddings
    command: >
      --hf-repo sudomoniker/all-MiniLM-L6-v2-Q8_0-GGUF
      --embeddings
      --host 0.0.0.0
      --port 8080
    # No external ports - internal only
    volumes:
      - embeddings_cache:/root/.cache
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      timeout: 5s
      retries: 3
      start_period: 30s

  # Atlas of Us Rust API
  api:
    image: atlas-of-us-api:latest
    container_name: atlas_rust_api
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      - EMBEDDING_ENDPOINT=http://embeddings:8080/embedding
      - NEO4J_URI=${NEO4J_URI}
      - NEO4J_USER=${NEO4J_USER}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - NEO4J_DATABASE=${NEO4J_DATABASE}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - ALLOWED_ORIGIN=${ALLOWED_ORIGIN}
      - S3_BUCKET=${S3_BUCKET}
      - AWS_REGION=${AWS_REGION}
    depends_on:
      embeddings:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/healthcheck"]
      timeout: 5s
      retries: 3
      start_period: 10s

volumes:
  embeddings_cache: